{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Basic introduction\n",
    "* Decision tree algorithm creates a tree like structure, in which branches originate when a decision is made.\n",
    "* The objective of this algorithm is to have the best dataset splits so that the resultant splitted datasets, are homogeneous.\n",
    "* This algorithm is a supervised learning algorithm.\n",
    "* Decision tree consists of two tpes of nodes:\n",
    "    * Decision Node/Non-leaf Node/Internal Node: At this node the dataset is split, i.e., the decision is made on the best split criteria.\n",
    "    * Leaf node: This node are the end/tail nodes that have final homogeneos dataset.\n",
    "* Basically the decision nodes are if/else conditions\n",
    "* Root Node: It is the best predictor among all the values of all the features.\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Splitting of the dataset can be done based on many metrics. But here we will disscuss two of them:\n",
    "1. Information Gain\n",
    "2. Gini Impurity/Gini Index\n",
    "\n",
    "Let us understand these metrics one by one."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Entropy**\n",
    "Entropy can be understood as:\n",
    "* Degree of randomness or chaos\n",
    "* Degree of purity or homogeneity\n",
    "\n",
    "Entropy (S) of a system can be formulated as:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"text-align:center\">\n",
    "  <img src=\"../images/ShanonEntropy.png\">\n",
    "</div>\n",
    "\n",
    "where,\n",
    "* N = Number of possible system states\n",
    "* P<sub>i</sub> = Probability of finding the system in i<sup>th</sup> state."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note:**\n",
    "* If the system is completely homogeneous, its entropy is zero.\n",
    "* Entropy is:\n",
    "    - Directly proportional to chaos\n",
    "    - Inversely proportional to the order of the system."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> *Objective of decision tree algorithm is to find the optimal values of the features at which we can split the dataset such that the entropy of the resulting subsets is less than the entropy of the original dataset.*\n",
    "\n",
    "This reduction of entropy is called as **Information Gain**. So we can reframe above statement as:\n",
    "\n",
    "> *Objective of decision tree algorithm is to find that value of the feature at which we can split the dataset such that the the information gain at that value is maximum.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Information gain can be formulated as,\n",
    "\n",
    "\n",
    "<div style=\"text-align:center\">\n",
    "  <img src=\"../images/InformationGain.png\">\n",
    "</div>\n",
    "\n",
    "where,\n",
    "* S<sub>o</sub> = Entropy before split\n",
    "* q = Number of splits\n",
    "* N<sub>i</sub> = Sample size of the i<sup>th</sup> resulting subset\n",
    "* S<sub>i</sub> = Entropy of the i<sup>th</sup> resulting subset\n",
    "* N = Sample size of the dataset before split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "#### Entropy Curve\n",
    "\n",
    "* Maximum value vaule attained by Entropy is 1\n",
    "\n",
    "<div style=\"text-align:center\">\n",
    "  <img src=\"../images/Entropy_Curve.png\">\n",
    "</div>\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Gini Impurity**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* It is the probability of incorrectly labelling a random element from a set.\n",
    "\n",
    "<div style=\"text-align:center\">\n",
    "  <img src=\"../images/Gini_Index.png\">\n",
    "</div>\n",
    "\n",
    "* where,\n",
    "    * j = number of possible classes\n",
    "    * <sub>j</sub> = probability of correctly classifying the outcome to class j.\n",
    "  \n",
    "\n",
    "* This metric is used in CART (Classification and Regression Trees)\n",
    "* It measures the inequality/impurity among values of a variable.\n",
    "* Understand Gini coefficient based on Lorenz curve that plots cumulative income of people against cumulative count of people in a population. This plot shows the inequality in the income distribution in the population. Here Gini coefficient is equal to the inequality A divided by total area (A + B), i.e., A/(A+B).\n",
    "\n",
    "<div style=\"text-align:center\">\n",
    "  <img src=\"../images/Economics_Gini_coefficient2.svg\"><br>\n",
    "  Source: <a href=\"https://en.wikipedia.org/wiki/Gini_coefficient#/media/File:Economics_Gini_coefficient2.svg\">Wikipedia</a>\n",
    "</div>\n",
    "\n",
    "* Gini coefficient is indirectly proportional to equality and directly proportional to impurity."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### Gini Curve\n",
    "\n",
    "* Maximum value vaule attained by Entropy is 0.5 (Think why. Answer is explained in second reference.)\n",
    "\n",
    "<div style=\"text-align:center\">\n",
    "  <img src=\"../images/Gini_Index_Curve.png\">\n",
    "</div>\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Resources\n",
    "\n",
    "* <a href = \"https://mlcourse.ai/articles/topic3-dt-knn/\">Mlcourse.ai</a>\n",
    "* A good article by Andrew Hershy on Medium. <a href = \"https://towardsdatascience.com/gini-index-vs-information-entropy-7a7e4fed3fcb\">Gini Index vs Information Entropy</a>\n",
    "* <a href = \"https://medium.com/@analyttica/gini-coefficient-or-gini-index-in-our-data-science-analytics-platform-d0408fc83772\">Gini Coefficient or Gini Index in our Data Science & Analytics platform</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
